{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook for experimenting with prompts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "## System imports\n",
    "import os\n",
    "\n",
    "## Data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "## LangChain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "## Misc\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "## Self-defined modules\n",
    "from utils import calculations, prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API keys (retrieved from .env file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load environment variables\n",
    "load_dotenv()\n",
    "assert os.environ['LANGCHAIN_API_KEY'], \"Please set the LANGCHAIN_API_KEY environment variable\"\n",
    "assert os.environ['GROQ_API_KEY'], \"Please set the GROQ_API_KEY environment variable\"\n",
    "assert os.environ['OPENAI_API_KEY'], \"Please set the OPENAI_API_KEY environment variable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update data sources based on your file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data sources\n",
    "DATA_DIR = \"../../data/raw\"\n",
    "DATA_CSV_PATH = DATA_DIR + \"/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data pre-processing\n",
    "df = pd.read_csv(DATA_CSV_PATH)\n",
    "\n",
    "df[\"CreateDate\"] = df[\"CreateDate\"].apply(lambda x: datetime.strptime(x, \"%d/%m/%Y %H:%M\"))\n",
    "df[\"DeleteDate\"] = df[\"DeleteDate\"].apply(lambda x: datetime.strptime(x, \"%d/%m/%Y %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'current': {'total_number_of_orders': 5000, 'total_volume_of_orders': 20176480, 'total_value_of_orders': 80582268.83}, 'average_historical': {'total_number_of_orders': 5000, 'total_volume_of_orders': 20176480, 'total_value_of_orders': 80582268.83}, 'percentage_difference': {'in_total_orders': 0.0, 'in_total_volume': 0.0, 'in_total_value': 0.0}}\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting metrics (similar to those on dashboard)\n",
    "bi1_overview, bi2_sector, bi3_capacity, bi4_lifetime, bi5_price_instruction, \\\n",
    "    bi6_trades_over_time, bi7_sankey_diagram = calculations.calculate_metrics(df)\n",
    "\n",
    "str(bi1_overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuring LLM\n",
    "groq_llm = ChatGroq(model=\"llama3-8b-8192\")\n",
    "openai_llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PromptTemplate to create a prompt, specifying the input variables to be replaced by data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format a prompt with the data\n",
    "example_template = \"\"\"\n",
    "    Generate a summary of the financial data.\n",
    "    Data required: {data}\n",
    "    Provide an example of output: {example}\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"data\", \"example\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "example_output = \"Today's revenue was $300, with costs of $50.\"\n",
    "\n",
    "example_chain = example_prompt | openai_llm | StrOutputParser()\n",
    "\n",
    "## Invoke the chain by filling in the input variables\n",
    "# print(example_chain.invoke({\"data\": bi1_overview, \"example\": example_output}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**Overview**  \\n'\n",
      " 'For the period of 11/01/2024 - 14/01/2024, there was a total of 5000 orders '\n",
      " 'placed. The Total Volume done for the day was 20,176,480, and the Total '\n",
      " 'Value was 80,582,268.83. This is the same compared to the previous 3 days, '\n",
      " 'which had 5000 orders placed with a Total Volume of 20,176,480 and Total '\n",
      " 'Value of 80,582,268.83.')\n",
      "{'average_historical': {'total_number_of_orders': 4000,\n",
      "                        'total_value_of_orders': 80582268.83,\n",
      "                        'total_volume_of_orders': 20176480},\n",
      " 'current': {'total_number_of_orders': 5000,\n",
      "             'total_value_of_orders': 80582268.83,\n",
      "             'total_volume_of_orders': 20176480},\n",
      " 'percentage_difference': {'in_total_orders': 20,\n",
      "                           'in_total_value': 0.0,\n",
      "                           'in_total_volume': 0.0}}\n",
      "('**Order Overview**  \\n'\n",
      " 'For the period of 11/01/2024 - 14/01/2024, there was a total of 5000 orders '\n",
      " 'placed. The Total Volume done for the day was 20,176,480, and the Total '\n",
      " 'Value was $80,582,268.83. This is higher compared to the previous 3 days, '\n",
      " 'which had 4000 orders placed with a Total Volume of 20,176,480 and Total '\n",
      " 'Value of $80,582,268.83.')\n"
     ]
    }
   ],
   "source": [
    "## try out the prompt for the Overview section\n",
    "overview_prompt_str = prompts.overview_order_prompt\n",
    "\n",
    "## Add a final sentence to include today's data\n",
    "overview_prompt_str += \"\"\"\n",
    "    Use the above template for today's data: {data}\n",
    "\"\"\"\n",
    "\n",
    "overview_prompt = PromptTemplate(\n",
    "    input_variables=[\"data\"],\n",
    "    template=overview_prompt_str\n",
    ")\n",
    "\n",
    "overview_chain = overview_prompt | openai_llm | StrOutputParser()\n",
    "\n",
    "pprint(overview_chain.invoke({\"data\": bi1_overview}))\n",
    "\n",
    "## Change up the imported data to have some varied output\n",
    "bi1_overview_new = bi1_overview.copy()\n",
    "bi1_overview_new[\"average_historical\"][\"total_number_of_orders\"] = 4000\n",
    "bi1_overview_new[\"percentage_difference\"][\"in_total_orders\"] = 20\n",
    "pprint(bi1_overview_new)\n",
    "\n",
    "pprint(overview_chain.invoke({\"data\": bi1_overview_new}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
